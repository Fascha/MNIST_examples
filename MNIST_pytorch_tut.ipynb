{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "http://cs231n.github.io/\n",
    "\n",
    "## RNN\n",
    "http://web.stanford.edu/class/cs224n/\n",
    "\n",
    "https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv\n",
    "\n",
    "## Siraj Raval\n",
    "https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A/videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "batch_size = 64\n",
    "test_batch_size = 10000\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "log_interval = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "? nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "? F.dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train() #sets module to training mode\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data) #forward pass\n",
    "#         loss = F.nll_loss(output, target) #negative log likelihood\n",
    "        loss = F.cross_entropy(output, target) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad(): #Disabling gradient calc is useful for inference, reduces memory consumption\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.383605\n",
      "Train Epoch: 1 [1024/60000 (2%)]\tLoss: 2.307981\n",
      "Train Epoch: 1 [2048/60000 (3%)]\tLoss: 2.258795\n",
      "Train Epoch: 1 [3072/60000 (5%)]\tLoss: 2.251578\n",
      "Train Epoch: 1 [4096/60000 (7%)]\tLoss: 2.220585\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.183869\n",
      "Train Epoch: 1 [6144/60000 (10%)]\tLoss: 2.134310\n",
      "Train Epoch: 1 [7168/60000 (12%)]\tLoss: 2.062712\n",
      "Train Epoch: 1 [8192/60000 (14%)]\tLoss: 1.830346\n",
      "Train Epoch: 1 [9216/60000 (15%)]\tLoss: 1.691538\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.339271\n",
      "Train Epoch: 1 [11264/60000 (19%)]\tLoss: 1.242369\n",
      "Train Epoch: 1 [12288/60000 (20%)]\tLoss: 1.208603\n",
      "Train Epoch: 1 [13312/60000 (22%)]\tLoss: 1.068041\n",
      "Train Epoch: 1 [14336/60000 (24%)]\tLoss: 1.354424\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1.136357\n",
      "Train Epoch: 1 [16384/60000 (27%)]\tLoss: 0.984626\n",
      "Train Epoch: 1 [17408/60000 (29%)]\tLoss: 0.906940\n",
      "Train Epoch: 1 [18432/60000 (31%)]\tLoss: 0.776091\n",
      "Train Epoch: 1 [19456/60000 (32%)]\tLoss: 0.815874\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.788628\n",
      "Train Epoch: 1 [21504/60000 (36%)]\tLoss: 1.085692\n",
      "Train Epoch: 1 [22528/60000 (38%)]\tLoss: 0.706538\n",
      "Train Epoch: 1 [23552/60000 (39%)]\tLoss: 0.583539\n",
      "Train Epoch: 1 [24576/60000 (41%)]\tLoss: 0.866169\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.719796\n",
      "Train Epoch: 1 [26624/60000 (44%)]\tLoss: 0.693006\n",
      "Train Epoch: 1 [27648/60000 (46%)]\tLoss: 0.605932\n",
      "Train Epoch: 1 [28672/60000 (48%)]\tLoss: 0.720992\n",
      "Train Epoch: 1 [29696/60000 (49%)]\tLoss: 0.783987\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.474829\n",
      "Train Epoch: 1 [31744/60000 (53%)]\tLoss: 0.640421\n",
      "Train Epoch: 1 [32768/60000 (55%)]\tLoss: 0.487131\n",
      "Train Epoch: 1 [33792/60000 (56%)]\tLoss: 0.456540\n",
      "Train Epoch: 1 [34816/60000 (58%)]\tLoss: 0.550094\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.484736\n",
      "Train Epoch: 1 [36864/60000 (61%)]\tLoss: 0.449921\n",
      "Train Epoch: 1 [37888/60000 (63%)]\tLoss: 0.406956\n",
      "Train Epoch: 1 [38912/60000 (65%)]\tLoss: 0.819918\n",
      "Train Epoch: 1 [39936/60000 (67%)]\tLoss: 0.594623\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.436597\n",
      "Train Epoch: 1 [41984/60000 (70%)]\tLoss: 0.468808\n",
      "Train Epoch: 1 [43008/60000 (72%)]\tLoss: 0.768429\n",
      "Train Epoch: 1 [44032/60000 (73%)]\tLoss: 0.696516\n",
      "Train Epoch: 1 [45056/60000 (75%)]\tLoss: 0.479527\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.439892\n",
      "Train Epoch: 1 [47104/60000 (78%)]\tLoss: 0.861930\n",
      "Train Epoch: 1 [48128/60000 (80%)]\tLoss: 0.614699\n",
      "Train Epoch: 1 [49152/60000 (82%)]\tLoss: 0.377642\n",
      "Train Epoch: 1 [50176/60000 (84%)]\tLoss: 0.543456\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.461215\n",
      "Train Epoch: 1 [52224/60000 (87%)]\tLoss: 0.450691\n",
      "Train Epoch: 1 [53248/60000 (89%)]\tLoss: 0.619573\n",
      "Train Epoch: 1 [54272/60000 (90%)]\tLoss: 0.528598\n",
      "Train Epoch: 1 [55296/60000 (92%)]\tLoss: 0.437300\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.453275\n",
      "Train Epoch: 1 [57344/60000 (96%)]\tLoss: 0.367141\n",
      "Train Epoch: 1 [58368/60000 (97%)]\tLoss: 0.391161\n",
      "Train Epoch: 1 [59392/60000 (99%)]\tLoss: 0.403019\n",
      "\n",
      "Test set: Average loss: 0.1853, Accuracy: 9473/10000 (95%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.380986\n",
      "Train Epoch: 2 [1024/60000 (2%)]\tLoss: 0.512913\n",
      "Train Epoch: 2 [2048/60000 (3%)]\tLoss: 0.579869\n",
      "Train Epoch: 2 [3072/60000 (5%)]\tLoss: 0.547743\n",
      "Train Epoch: 2 [4096/60000 (7%)]\tLoss: 0.403976\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.278874\n",
      "Train Epoch: 2 [6144/60000 (10%)]\tLoss: 0.491255\n",
      "Train Epoch: 2 [7168/60000 (12%)]\tLoss: 0.374611\n",
      "Train Epoch: 2 [8192/60000 (14%)]\tLoss: 0.404194\n",
      "Train Epoch: 2 [9216/60000 (15%)]\tLoss: 0.348478\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.451538\n",
      "Train Epoch: 2 [11264/60000 (19%)]\tLoss: 0.252518\n",
      "Train Epoch: 2 [12288/60000 (20%)]\tLoss: 0.327134\n",
      "Train Epoch: 2 [13312/60000 (22%)]\tLoss: 0.402051\n",
      "Train Epoch: 2 [14336/60000 (24%)]\tLoss: 0.321326\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.362908\n",
      "Train Epoch: 2 [16384/60000 (27%)]\tLoss: 0.402375\n",
      "Train Epoch: 2 [17408/60000 (29%)]\tLoss: 0.338524\n",
      "Train Epoch: 2 [18432/60000 (31%)]\tLoss: 0.423347\n",
      "Train Epoch: 2 [19456/60000 (32%)]\tLoss: 0.461656\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.349632\n",
      "Train Epoch: 2 [21504/60000 (36%)]\tLoss: 0.440200\n",
      "Train Epoch: 2 [22528/60000 (38%)]\tLoss: 0.320454\n",
      "Train Epoch: 2 [23552/60000 (39%)]\tLoss: 0.412386\n",
      "Train Epoch: 2 [24576/60000 (41%)]\tLoss: 0.467618\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.471875\n",
      "Train Epoch: 2 [26624/60000 (44%)]\tLoss: 0.361452\n",
      "Train Epoch: 2 [27648/60000 (46%)]\tLoss: 0.260875\n",
      "Train Epoch: 2 [28672/60000 (48%)]\tLoss: 0.218834\n",
      "Train Epoch: 2 [29696/60000 (49%)]\tLoss: 0.222912\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.250809\n",
      "Train Epoch: 2 [31744/60000 (53%)]\tLoss: 0.499345\n",
      "Train Epoch: 2 [32768/60000 (55%)]\tLoss: 0.201124\n",
      "Train Epoch: 2 [33792/60000 (56%)]\tLoss: 0.416926\n",
      "Train Epoch: 2 [34816/60000 (58%)]\tLoss: 0.408878\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.149479\n",
      "Train Epoch: 2 [36864/60000 (61%)]\tLoss: 0.268966\n",
      "Train Epoch: 2 [37888/60000 (63%)]\tLoss: 0.412662\n",
      "Train Epoch: 2 [38912/60000 (65%)]\tLoss: 0.555418\n",
      "Train Epoch: 2 [39936/60000 (67%)]\tLoss: 0.418836\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.643101\n",
      "Train Epoch: 2 [41984/60000 (70%)]\tLoss: 0.304606\n",
      "Train Epoch: 2 [43008/60000 (72%)]\tLoss: 0.361416\n",
      "Train Epoch: 2 [44032/60000 (73%)]\tLoss: 0.248166\n",
      "Train Epoch: 2 [45056/60000 (75%)]\tLoss: 0.308072\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.138989\n",
      "Train Epoch: 2 [47104/60000 (78%)]\tLoss: 0.289737\n",
      "Train Epoch: 2 [48128/60000 (80%)]\tLoss: 0.346088\n",
      "Train Epoch: 2 [49152/60000 (82%)]\tLoss: 0.255391\n",
      "Train Epoch: 2 [50176/60000 (84%)]\tLoss: 0.181949\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.476447\n",
      "Train Epoch: 2 [52224/60000 (87%)]\tLoss: 0.386443\n",
      "Train Epoch: 2 [53248/60000 (89%)]\tLoss: 0.121004\n",
      "Train Epoch: 2 [54272/60000 (90%)]\tLoss: 0.270793\n",
      "Train Epoch: 2 [55296/60000 (92%)]\tLoss: 0.218488\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.299930\n",
      "Train Epoch: 2 [57344/60000 (96%)]\tLoss: 0.330185\n",
      "Train Epoch: 2 [58368/60000 (97%)]\tLoss: 0.505783\n",
      "Train Epoch: 2 [59392/60000 (99%)]\tLoss: 0.243404\n",
      "\n",
      "Test set: Average loss: 0.1140, Accuracy: 9651/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.360032\n",
      "Train Epoch: 3 [1024/60000 (2%)]\tLoss: 0.305610\n",
      "Train Epoch: 3 [2048/60000 (3%)]\tLoss: 0.285537\n",
      "Train Epoch: 3 [3072/60000 (5%)]\tLoss: 0.233855\n",
      "Train Epoch: 3 [4096/60000 (7%)]\tLoss: 0.330339\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.287342\n",
      "Train Epoch: 3 [6144/60000 (10%)]\tLoss: 0.246372\n",
      "Train Epoch: 3 [7168/60000 (12%)]\tLoss: 0.247127\n",
      "Train Epoch: 3 [8192/60000 (14%)]\tLoss: 0.330894\n",
      "Train Epoch: 3 [9216/60000 (15%)]\tLoss: 0.240021\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.305522\n",
      "Train Epoch: 3 [11264/60000 (19%)]\tLoss: 0.422962\n",
      "Train Epoch: 3 [12288/60000 (20%)]\tLoss: 0.376394\n",
      "Train Epoch: 3 [13312/60000 (22%)]\tLoss: 0.204442\n",
      "Train Epoch: 3 [14336/60000 (24%)]\tLoss: 0.203972\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.326439\n",
      "Train Epoch: 3 [16384/60000 (27%)]\tLoss: 0.210784\n",
      "Train Epoch: 3 [17408/60000 (29%)]\tLoss: 0.334859\n",
      "Train Epoch: 3 [18432/60000 (31%)]\tLoss: 0.370084\n",
      "Train Epoch: 3 [19456/60000 (32%)]\tLoss: 0.440695\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.230297\n",
      "Train Epoch: 3 [21504/60000 (36%)]\tLoss: 0.101483\n",
      "Train Epoch: 3 [22528/60000 (38%)]\tLoss: 0.356439\n",
      "Train Epoch: 3 [23552/60000 (39%)]\tLoss: 0.173399\n",
      "Train Epoch: 3 [24576/60000 (41%)]\tLoss: 0.319819\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.453241\n",
      "Train Epoch: 3 [26624/60000 (44%)]\tLoss: 0.268436\n",
      "Train Epoch: 3 [27648/60000 (46%)]\tLoss: 0.166886\n",
      "Train Epoch: 3 [28672/60000 (48%)]\tLoss: 0.192531\n",
      "Train Epoch: 3 [29696/60000 (49%)]\tLoss: 0.294780\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.230559\n",
      "Train Epoch: 3 [31744/60000 (53%)]\tLoss: 0.222346\n",
      "Train Epoch: 3 [32768/60000 (55%)]\tLoss: 0.151216\n",
      "Train Epoch: 3 [33792/60000 (56%)]\tLoss: 0.165848\n",
      "Train Epoch: 3 [34816/60000 (58%)]\tLoss: 0.428252\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.253560\n",
      "Train Epoch: 3 [36864/60000 (61%)]\tLoss: 0.284264\n",
      "Train Epoch: 3 [37888/60000 (63%)]\tLoss: 0.093375\n",
      "Train Epoch: 3 [38912/60000 (65%)]\tLoss: 0.209621\n",
      "Train Epoch: 3 [39936/60000 (67%)]\tLoss: 0.333939\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.313938\n",
      "Train Epoch: 3 [41984/60000 (70%)]\tLoss: 0.360962\n",
      "Train Epoch: 3 [43008/60000 (72%)]\tLoss: 0.333112\n",
      "Train Epoch: 3 [44032/60000 (73%)]\tLoss: 0.227304\n",
      "Train Epoch: 3 [45056/60000 (75%)]\tLoss: 0.228579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.350005\n",
      "Train Epoch: 3 [47104/60000 (78%)]\tLoss: 0.643657\n",
      "Train Epoch: 3 [48128/60000 (80%)]\tLoss: 0.292666\n",
      "Train Epoch: 3 [49152/60000 (82%)]\tLoss: 0.305131\n",
      "Train Epoch: 3 [50176/60000 (84%)]\tLoss: 0.147939\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.391049\n",
      "Train Epoch: 3 [52224/60000 (87%)]\tLoss: 0.207508\n",
      "Train Epoch: 3 [53248/60000 (89%)]\tLoss: 0.272734\n",
      "Train Epoch: 3 [54272/60000 (90%)]\tLoss: 0.197940\n",
      "Train Epoch: 3 [55296/60000 (92%)]\tLoss: 0.237534\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.320474\n",
      "Train Epoch: 3 [57344/60000 (96%)]\tLoss: 0.303955\n",
      "Train Epoch: 3 [58368/60000 (97%)]\tLoss: 0.256656\n",
      "Train Epoch: 3 [59392/60000 (99%)]\tLoss: 0.451116\n",
      "\n",
      "Test set: Average loss: 0.0870, Accuracy: 9725/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.177527\n",
      "Train Epoch: 4 [1024/60000 (2%)]\tLoss: 0.362940\n",
      "Train Epoch: 4 [2048/60000 (3%)]\tLoss: 0.331656\n",
      "Train Epoch: 4 [3072/60000 (5%)]\tLoss: 0.256799\n",
      "Train Epoch: 4 [4096/60000 (7%)]\tLoss: 0.224397\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.362155\n",
      "Train Epoch: 4 [6144/60000 (10%)]\tLoss: 0.220808\n",
      "Train Epoch: 4 [7168/60000 (12%)]\tLoss: 0.259170\n",
      "Train Epoch: 4 [8192/60000 (14%)]\tLoss: 0.263280\n",
      "Train Epoch: 4 [9216/60000 (15%)]\tLoss: 0.148975\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.365275\n",
      "Train Epoch: 4 [11264/60000 (19%)]\tLoss: 0.426966\n",
      "Train Epoch: 4 [12288/60000 (20%)]\tLoss: 0.383575\n",
      "Train Epoch: 4 [13312/60000 (22%)]\tLoss: 0.302236\n",
      "Train Epoch: 4 [14336/60000 (24%)]\tLoss: 0.093273\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.176148\n",
      "Train Epoch: 4 [16384/60000 (27%)]\tLoss: 0.199859\n",
      "Train Epoch: 4 [17408/60000 (29%)]\tLoss: 0.313144\n",
      "Train Epoch: 4 [18432/60000 (31%)]\tLoss: 0.253216\n",
      "Train Epoch: 4 [19456/60000 (32%)]\tLoss: 0.280839\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.231622\n",
      "Train Epoch: 4 [21504/60000 (36%)]\tLoss: 0.127243\n",
      "Train Epoch: 4 [22528/60000 (38%)]\tLoss: 0.195850\n",
      "Train Epoch: 4 [23552/60000 (39%)]\tLoss: 0.473765\n",
      "Train Epoch: 4 [24576/60000 (41%)]\tLoss: 0.298613\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.166769\n",
      "Train Epoch: 4 [26624/60000 (44%)]\tLoss: 0.237989\n",
      "Train Epoch: 4 [27648/60000 (46%)]\tLoss: 0.096792\n",
      "Train Epoch: 4 [28672/60000 (48%)]\tLoss: 0.216233\n",
      "Train Epoch: 4 [29696/60000 (49%)]\tLoss: 0.226822\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.084416\n",
      "Train Epoch: 4 [31744/60000 (53%)]\tLoss: 0.208151\n",
      "Train Epoch: 4 [32768/60000 (55%)]\tLoss: 0.318667\n",
      "Train Epoch: 4 [33792/60000 (56%)]\tLoss: 0.440655\n",
      "Train Epoch: 4 [34816/60000 (58%)]\tLoss: 0.263379\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.262195\n",
      "Train Epoch: 4 [36864/60000 (61%)]\tLoss: 0.163212\n",
      "Train Epoch: 4 [37888/60000 (63%)]\tLoss: 0.445665\n",
      "Train Epoch: 4 [38912/60000 (65%)]\tLoss: 0.219488\n",
      "Train Epoch: 4 [39936/60000 (67%)]\tLoss: 0.307938\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.587794\n",
      "Train Epoch: 4 [41984/60000 (70%)]\tLoss: 0.263828\n",
      "Train Epoch: 4 [43008/60000 (72%)]\tLoss: 0.285411\n",
      "Train Epoch: 4 [44032/60000 (73%)]\tLoss: 0.486593\n",
      "Train Epoch: 4 [45056/60000 (75%)]\tLoss: 0.199350\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.337214\n",
      "Train Epoch: 4 [47104/60000 (78%)]\tLoss: 0.244428\n",
      "Train Epoch: 4 [48128/60000 (80%)]\tLoss: 0.314391\n",
      "Train Epoch: 4 [49152/60000 (82%)]\tLoss: 0.163313\n",
      "Train Epoch: 4 [50176/60000 (84%)]\tLoss: 0.114171\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.290791\n",
      "Train Epoch: 4 [52224/60000 (87%)]\tLoss: 0.220729\n",
      "Train Epoch: 4 [53248/60000 (89%)]\tLoss: 0.322515\n",
      "Train Epoch: 4 [54272/60000 (90%)]\tLoss: 0.177198\n",
      "Train Epoch: 4 [55296/60000 (92%)]\tLoss: 0.175302\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.254170\n",
      "Train Epoch: 4 [57344/60000 (96%)]\tLoss: 0.157789\n",
      "Train Epoch: 4 [58368/60000 (97%)]\tLoss: 0.225687\n",
      "Train Epoch: 4 [59392/60000 (99%)]\tLoss: 0.282468\n",
      "\n",
      "Test set: Average loss: 0.0739, Accuracy: 9758/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "? torch.no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
